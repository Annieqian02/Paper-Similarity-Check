{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5ce8d5d",
   "metadata": {},
   "source": [
    "# Paper Similarity Check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc864fca",
   "metadata": {},
   "source": [
    "Python Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7abf2185",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/annieqian/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/annieqian/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import PyPDF2\n",
    "import nltk\n",
    "import csv\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ac9b2a",
   "metadata": {},
   "source": [
    "Making sure download the nltk package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e10eb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.data.path.append(\"./nltk_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57e7ba8",
   "metadata": {},
   "source": [
    "Turing pdf to text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d1f6d683",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(file_path):\n",
    "    pdf_reader = PyPDF2.PdfReader(open(file_path, 'rb'))\n",
    "    text = ''\n",
    "    for page_num in range(len(pdf_reader.pages)):\n",
    "        text += pdf_reader.pages[page_num].extract_text()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f1a93b",
   "metadata": {},
   "source": [
    "Finding matched files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f00901ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_and_compare_files(directory):\n",
    "    # Create a dictionary to store files based on their base name\n",
    "    file_dict = defaultdict(list)\n",
    "    \n",
    "    # Define the regex pattern to extract the base name and the number\n",
    "    pattern = re.compile(r'^(.*)_(\\d+)\\.pdf$')\n",
    "\n",
    "    # Iterate through files in the directory\n",
    "    for filename in os.listdir(directory):\n",
    "        match = pattern.match(filename)\n",
    "        if match:\n",
    "            base_name = match.group(1)\n",
    "            number = int(match.group(2))\n",
    "            file_dict[base_name].append((number, filename))\n",
    "    \n",
    "    # Find matching pairs: basename_0 vs other basename files\n",
    "    matching_pairs = defaultdict(list)\n",
    "    for base_name, files in file_dict.items():\n",
    "        draft_0 = None\n",
    "        other_drafts = []\n",
    "        \n",
    "        for file in files:\n",
    "            if file[0] == 0:\n",
    "                draft_0 = file[1]\n",
    "            else:\n",
    "                other_drafts.append((file[0], file[1]))\n",
    "        \n",
    "        # Add pairings of draft_0 with each other draft\n",
    "        if draft_0:\n",
    "            for number, other_draft in other_drafts:\n",
    "                matching_pairs[base_name].append((draft_0, other_draft, number))\n",
    "\n",
    "    return matching_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d641791",
   "metadata": {},
   "source": [
    "Computing Similarity Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1e292ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarity(first_draft_path, final_draft_path):\n",
    "    # Extract text from both PDFs\n",
    "    first_draft_text = extract_text_from_pdf(first_draft_path)\n",
    "    final_draft_text = extract_text_from_pdf(final_draft_path)\n",
    "\n",
    "    documents = [first_draft_text, final_draft_text]\n",
    "\n",
    "    stop_words = stopwords.words('english')\n",
    "\n",
    "    word_tokenizer = WordPunctTokenizer()\n",
    "    word_lemmatizer = nltk.WordNetLemmatizer()\n",
    "\n",
    "    vocabulary_dict = defaultdict(int)\n",
    "    cleansed_documents = []\n",
    "    for doc in documents:\n",
    "        tokens = word_tokenizer.tokenize(doc)\n",
    "        alpha_words = [word.lower() for word in tokens if word.isalpha() and len(word) > 2 and word not in stop_words]\n",
    "        final_words = [word_lemmatizer.lemmatize(word) for word in alpha_words]\n",
    "        for word in final_words:\n",
    "            vocabulary_dict[word] += 1\n",
    "        cleansed_doc = ' '.join(final_words)\n",
    "        cleansed_documents.append(cleansed_doc)\n",
    "\n",
    "    sorted_vocabulary = [word for word, _ in sorted(vocabulary_dict.items(), key=lambda kv: kv[1], reverse=True)]\n",
    "        \n",
    "    word_vectorizer = TfidfVectorizer(vocabulary=sorted_vocabulary)\n",
    "    matrix = word_vectorizer.fit_transform(cleansed_documents).toarray()\n",
    "    \n",
    "    # Compute the cosine similarity\n",
    "    first_doc = matrix[0].reshape(1, -1)\n",
    "    next_doc = matrix[1].reshape(1, -1)\n",
    "    similarity_score = cosine_similarity(first_doc, next_doc)\n",
    "    \n",
    "    return similarity_score[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589f66bd",
   "metadata": {},
   "source": [
    "Put your directory path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "544e2c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory path\n",
    "directory_path = '/Users/annieqian/Desktop/check_similarity/test_1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be29c8d7",
   "metadata": {},
   "source": [
    "Run the code and Print out the Similarity Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "32c8a59b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity scores have been saved to /Users/annieqian/Desktop/check_similarity/similarity_scores.csv\n"
     ]
    }
   ],
   "source": [
    "matching_files = find_and_compare_files(directory_path)\n",
    "\n",
    "# Prepare the data for the CSV\n",
    "csv_data = []\n",
    "header = ['basename']\n",
    "\n",
    "# Compute similarity scores and store them\n",
    "for base_name, pairs in matching_files.items():\n",
    "    row = {'basename': base_name}\n",
    "    for draft_0, other_draft, number in pairs:\n",
    "        if draft_0:  # Only process if draft_0 exists\n",
    "            similarity_score = compute_similarity(os.path.join(directory_path, draft_0), os.path.join(directory_path, other_draft))\n",
    "            column_name = f'score_0_{number}'\n",
    "            row[column_name] = similarity_score\n",
    "            if column_name not in header:\n",
    "                header.append(column_name)\n",
    "    csv_data.append(row)\n",
    "\n",
    "# Write to CSV file\n",
    "csv_file_path = '/Users/annieqian/Desktop/check_similarity/similarity_scores.csv'\n",
    "with open(csv_file_path, 'w', newline='') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=header)\n",
    "    writer.writeheader()\n",
    "    for data in csv_data:\n",
    "        writer.writerow(data)\n",
    "\n",
    "print(f\"Similarity scores have been saved to {csv_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a120d16a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
