{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5ce8d5d",
   "metadata": {},
   "source": [
    "# Paper Similarity Check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc864fca",
   "metadata": {},
   "source": [
    "Python Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7abf2185",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/annieqian/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/annieqian/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import PyPDF2\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ac9b2a",
   "metadata": {},
   "source": [
    "Making sure download the nltk package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e10eb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.data.path.append(\"./nltk_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57e7ba8",
   "metadata": {},
   "source": [
    "Turing pdf to text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1f6d683",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(file_path):\n",
    "    pdf_reader = PyPDF2.PdfReader(open(file_path, 'rb'))\n",
    "    text = ''\n",
    "    for page_num in range(len(pdf_reader.pages)):\n",
    "        text += pdf_reader.pages[page_num].extract_text()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f1a93b",
   "metadata": {},
   "source": [
    "Finding matched files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f00901ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_and_compare_files(directory):\n",
    "    # Create a dictionary to store files based on their base name\n",
    "    file_dict = defaultdict(list)\n",
    "    \n",
    "    # Define the regex pattern to extract the base name and the number\n",
    "    pattern = re.compile(r'^(.*)_(\\d+)\\.pdf$')\n",
    "\n",
    "    # Iterate through files in the directory\n",
    "    for filename in os.listdir(directory):\n",
    "        match = pattern.match(filename)\n",
    "        if match:\n",
    "            base_name = match.group(1)\n",
    "            number = int(match.group(2))\n",
    "            file_dict[base_name].append((number, filename))\n",
    "    \n",
    "    # Find matching pairs\n",
    "    matching_pairs = []\n",
    "    for base_name, files in file_dict.items():\n",
    "        files_sorted = sorted(files, key=lambda x: x[0])\n",
    "        for i in range(len(files_sorted) - 1):\n",
    "            current_file = files_sorted[i]\n",
    "            next_file = files_sorted[i + 1]\n",
    "            if next_file[0] == current_file[0] + 1:\n",
    "                matching_pairs.append((current_file[1], next_file[1]))\n",
    "\n",
    "    return matching_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d641791",
   "metadata": {},
   "source": [
    "Computing Similarity Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e292ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_similarity(first_draft_path, final_draft_path):\n",
    "    # Extract text from both PDFs\n",
    "    first_draft_text = extract_text_from_pdf(first_draft_path)\n",
    "    final_draft_text = extract_text_from_pdf(final_draft_path)\n",
    "\n",
    "    documents = [first_draft_text, final_draft_text]\n",
    "\n",
    "    stop_words = stopwords.words('english')\n",
    "\n",
    "    word_tokenizer = WordPunctTokenizer()\n",
    "    word_lemmatizer = nltk.WordNetLemmatizer()\n",
    "\n",
    "    vocabulary_dict = defaultdict(int)\n",
    "    cleansed_documents = []\n",
    "    for doc in documents:\n",
    "        tokens = word_tokenizer.tokenize(doc)\n",
    "        alpha_words = [word.lower() for word in tokens if word.isalpha() and len(word) > 2 and word not in stop_words]\n",
    "        final_words = [word_lemmatizer.lemmatize(word) for word in alpha_words]\n",
    "        for word in final_words:\n",
    "            vocabulary_dict[word] += 1\n",
    "        cleansed_doc = ' '.join(final_words)\n",
    "        cleansed_documents.append(cleansed_doc)\n",
    "\n",
    "    sorted_vocabulary = sorted(vocabulary_dict.items(), key=lambda kv: kv[1], reverse=True)\n",
    "\n",
    "    vocabulary = []\n",
    "    for word, count in sorted_vocabulary:\n",
    "        vocabulary.append(word)\n",
    "        \n",
    "    word_vectorizer = TfidfVectorizer(vocabulary=vocabulary)\n",
    "    matrix = word_vectorizer.fit_transform(cleansed_documents).toarray()\n",
    "    #compute the cosine similarity\n",
    "    first_doc = matrix[0].reshape(1, -1)\n",
    "    next_doc = matrix[1].reshape(1, -1)\n",
    "    similarity_score = cosine_similarity(first_doc, next_doc)\n",
    "    \n",
    "    return similarity_score[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589f66bd",
   "metadata": {},
   "source": [
    "Put your directory path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "544e2c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory path\n",
    "directory_path = '/Users/annieqian/Desktop/check_similarity/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be29c8d7",
   "metadata": {},
   "source": [
    "Run the code and Print out the Similarity Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32c8a59b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched files: a803f_0.pdf and a803f_1.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annieqian/anaconda3/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:1375: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity score between a803f_0.pdf and a803f_1.pdf: 0.9865\n",
      "Matched files: a8768_0.pdf and a8768_1.pdf\n",
      "Similarity score between a8768_0.pdf and a8768_1.pdf: 0.7863\n",
      "Matched files: a8768_1.pdf and a8768_2.pdf\n",
      "Similarity score between a8768_1.pdf and a8768_2.pdf: 0.9938\n"
     ]
    }
   ],
   "source": [
    "# Find the matching files\n",
    "matching_files = find_and_compare_files(directory_path)\n",
    "\n",
    "# Compute and print the similarity scores\n",
    "for pair in matching_files:\n",
    "    first_draft_path = os.path.join(directory_path, pair[0])\n",
    "    final_draft_path = os.path.join(directory_path, pair[1])\n",
    "    print(f\"Matched files: {pair[0]} and {pair[1]}\")\n",
    "    similarity_score = compute_similarity(first_draft_path, final_draft_path)\n",
    "    print(f\"Similarity score between {pair[0]} and {pair[1]}: {similarity_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a120d16a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
